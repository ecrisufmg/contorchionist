#N canvas 850 52 819 1000 12;
#X obj -5 29 cnv 3 800 3 empty empty description 12 12 0 14 #7c7c7c #404040 0;
#X obj -5 87 cnv 3 800 3 empty empty inlets 8 12 0 13 #dcdcdc #000000 0;
#X obj 77 93 cnv 18 3 17 empty empty 0 5 9 0 14 #dcdcdc #9c9c9c 0;
#X obj -5 362 cnv 3 800 3 empty empty outlets 8 12 0 13 #dcdcdc #000000 0;
#X obj 77 370 cnv 18 3 17 empty empty 0 5 9 0 14 #dcdcdc #9c9c9c 0;
#X obj -6 646 cnv 3 800 3 empty empty example 8 12 0 13 #dcdcdc #000000 0;
#X obj -6 1 cnv 3 800 3 empty empty torch.sequential 14 14 1 22 #7c7c7c #404040 0;
#X text 734 10 v.0.1.0;
#X text 654 66 tested on pd-0.56-1;
#X text 99 370 list:;
#X obj -5 415 cnv 3 800 3 empty empty arguments 8 12 0 13 #dcdcdc #000000 0;
#X obj -6 557 cnv 3 800 3 empty empty flags 8 12 0 13 #dcdcdc #000000 0;
#X text 93 624 -verbose: enable verbose logging printings;
#N canvas 294 25 1183 557 (subpatch) 0;
#X obj 385 43 pdcontrol;
#X obj 13 8 inlet;
#X msg 14 40 browse https://github.com/ecrisufmg/contorchionist;
#X connect 1 0 2 0;
#X connect 2 0 0 0;
#X coords 0 -1 1 1 4 2 2 1 1;
#X restore 689 56 pd;
#X msg 689 40 conTorchinist;
#X text 106 96 incoming data: [list];
#X text 274 95 float list of incoming data;
#X text 110 334 device: [symbol];
#X text 280 333 sets the device: cpu \, cuda or mps;
#X text 93 564 -d: sets the device: cpu \, cuda or mps (default=cpu);
#X msg 203 881 train 300;
#X msg 183 774 target \$1;
#X obj 183 750 tgl 19 0 empty empty empty 0 -10 0 12 #fcfcfc #000000 #000000 0 1;
#X text 388 851 load a dataset from .txt file;
#X msg 173 722 loss mse;
#X text 245 722 set the loss function;
#X text 261 758 sets target=1 \, if the dataset has target/label or sets target=0 \, if the dataset has no target/label (default=0), f 51;
#X msg 197 850 load data/modelo_test.txt;
#X text 262 810 set a torch.ls2tensor tensor to use it as training dataset, f 48;
#X msg 194 815 dataset;
#X text 97 45 creates and trains models built by sequential layers added to its named container, f 52;
#X text 108 116 set: [symbol];
#X text 275 116 creates a new container with a specified name;
#X text 108 136 clear: [message];
#X text 275 136 destroy the current container and re-create a new with the same name, f 69;
#X text 108 158 optimizer: [symbol];
#X text 275 158 sets the optimizer algorithm and the learning rate;
#X text 108 181 loss: [symbol];
#X text 277 179 set the loss function;
#X text 108 205 target: [integer];
#X text 276 198 enables/disables target: 1 \, if the dataset has target/label \, 0 if the dataset has no target/label;
#X text 109 230 train: [integer];
#X text 277 231 train the model through the number of epochs specified;
#X text 110 251 dataset: [symbol];
#X text 276 251 sets a torch.ls2tensor tensor to use it as training dataset;
#X text 110 272 load: [symbol];
#X text 276 272 loads a training dataset from .txt file;
#X text 110 295 init: [symbol];
#X text 277 295 initializes the layers weights with the specified method;
#X text 110 315 info: [message];
#X text 278 314 print all the layers added to the container;
#X text 144 371 forward output;
#X text 145 394 training loss values;
#X text 94 422 -name: sets the container name;
#X text 97 498 -weight initialization: he uniform \, he normal \, xavier uniform \, xavier normal \, uniform \, normal \, constant (default=uniform-low=0 \, high=1), f 97;
#X text 97 532 -random state (default=-1);
#X text 94 584 -target: sets target for supervised models (default=false);
#X text 95 462 -learning_rate (default=1e-03);
#X obj 146 922 torch.sequential module1 -optimizer adam -loss mse -learning_rate 0.0001 -init normal mean 0 std 0.01 -target -d mps -v;
#X text 95 605 -outloss: returns the loss value when training is finished (default=false), f 74;
#N canvas 381 117 450 300 other_messages 0;
#X text 55 60 initialize the layers weights with a specified method, f 32;
#X text 5 101 he uniform: nonlinearity negative slope (default: relu 0) he normal: nonlinearity negative slope (default: leaky_relu 0.2) xavier uniform: gain (defalt: 1) uniform: low high (default: 0 1) normal mean: std (default: 0 0.02) constant: value (default: 0), f 63;
#X text -255 191 -loss function: mse \, l1 \, smooth l1 \, cross entropy \, nll \, binary cross entropy \, binary cross entropy with logits \, kl divergence \, hinge embendding \, multi margin \, multi label margin \, multi label soft margin \, soft margin (default=mse), f 95;
#X text 77 239 adam \, adamw \, adagrad \, lbfgs \, rmsprop \, sgd;
#X restore 611 693 pd other_messages;
#X text 96 480 -loss function: sets the loss function (default=mse), f 95;
#X text 94 442 -optimizer: sets the opitimizer (default=sgd), f 97;
#X msg 158 693 optimizer adam 0.001;
#X text 308 692 sets the optimizer and learning rate;
#X msg 145 664 set module-\$0;
#X text 250 665 sets the container name;
#X connect 14 0 13 0;
#X connect 20 0 58 0;
#X connect 21 0 58 0;
#X connect 22 0 21 0;
#X connect 24 0 58 0;
#X connect 27 0 58 0;
#X connect 29 0 58 0;
#X connect 63 0 58 0;
#X connect 65 0 58 0;
